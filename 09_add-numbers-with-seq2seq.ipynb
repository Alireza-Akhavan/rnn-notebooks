{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
    "<img src=\"./logo.png\" alt=\"class.vision\" style=\"width: 200px;\"/>\n",
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">Seq2Seq برای جمع  اعداد!</div></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from math import ceil\n",
    "from math import log10\n",
    "from math import sqrt\n",
    "from numpy import argmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "    X, y = list(), list()\n",
    "    for i in range(n_examples):\n",
    "        in_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "        out_pattern = sum(in_pattern)\n",
    "        X.append(in_pattern)\n",
    "        y.append(out_pattern)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[12, 3, 4]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "x,y = random_sum_pairs(100,3,15)\n",
    "print(len(x))\n",
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "    max_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1\n",
    "    Xstr = list()\n",
    "    for pattern in X:\n",
    "        strp = '+'.join([str(n) for n in pattern])\n",
    "        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "        Xstr.append(strp)\n",
    "    max_length = ceil(log10(n_numbers * (largest+1)))\n",
    "    ystr = list()\n",
    "    for pattern in y:\n",
    "        strp = str(pattern)\n",
    "        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "        ystr.append(strp)\n",
    "    return Xstr, ystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    Xenc = list()\n",
    "    for pattern in X:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        Xenc.append(integer_encoded)\n",
    "    yenc = list()\n",
    "    for pattern in y:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        yenc.append(integer_encoded)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # one hot encode\n",
    "def one_hot_encode(X, y, max_int):\n",
    "    Xenc = list()\n",
    "    for seq in X:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        Xenc.append(pattern)\n",
    "    yenc = list()\n",
    "    for seq in y:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        yenc.append(pattern)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an encoded dataset\n",
    "def generate_data(n_samples, n_numbers, largest, alphabet):\n",
    "    # generate pairs\n",
    "    X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "    # convert to strings\n",
    "    X, y = to_string(X, y, n_numbers, largest)\n",
    "    # integer encode\n",
    "    X, y = integer_encode(X, y, alphabet)\n",
    "    # one hot encode\n",
    "    X, y = one_hot_encode(X, y, len(alphabet))\n",
    "    # return as numpy arrays\n",
    "    X, y = array(X), array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert encoding\n",
    "def invert(seq, alphabet):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    strings = list()\n",
    "    for pattern in seq:\n",
    "        string = int_to_char[argmax(pattern)]\n",
    "        strings.append(string)\n",
    "    return ''.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "seed(1)\n",
    "n_samples = 1000\n",
    "n_numbers = 2\n",
    "largest = 10\n",
    "alphabet = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', ' ']\n",
    "n_chars = len(alphabet)\n",
    "n_in_seq_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1\n",
    "n_out_seq_length = ceil(log10(n_numbers * (largest+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_data(n_samples, n_numbers, largest, alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (1000, 5, 12)\n",
      "shape of y (1000, 2, 12)\n",
      "X[0]:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "y[0]\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]]\n",
      "invert X[0]  3+10\n",
      "invert y[0] 13\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X\", X.shape)\n",
    "print(\"shape of y\", y.shape)\n",
    "print(\"X[0]:\")\n",
    "print(X[0])\n",
    "print(\"y[0]\")\n",
    "print(y[0])\n",
    "\n",
    "print(\"invert X[0]\", invert(X[0], alphabet) )\n",
    "print(\"invert y[0]\", invert(y[0], alphabet) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LSTM configuration\n",
    "n_batch = 10\n",
    "n_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               45200     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 2, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 2, 50)             30200     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 12)             612       \n",
      "=================================================================\n",
      "Total params: 76,012\n",
      "Trainable params: 76,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.9967 - accuracy: 0.3445\n",
      "1\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5194 - accuracy: 0.3680\n",
      "2\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3945 - accuracy: 0.4670\n",
      "3\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3099 - accuracy: 0.5075\n",
      "4\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1971 - accuracy: 0.5595\n",
      "5\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0768 - accuracy: 0.6285\n",
      "6\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9106 - accuracy: 0.6870\n",
      "7\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7884 - accuracy: 0.7330\n",
      "8\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6850 - accuracy: 0.8075\n",
      "9\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5964 - accuracy: 0.8660\n",
      "10\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5245 - accuracy: 0.8975\n",
      "11\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4445 - accuracy: 0.9350\n",
      "12\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3942 - accuracy: 0.9580\n",
      "13\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3604 - accuracy: 0.9520\n",
      "14\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3117 - accuracy: 0.9580\n",
      "15\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2776 - accuracy: 0.9790\n",
      "16\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2440 - accuracy: 0.9800\n",
      "17\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2322 - accuracy: 0.9855\n",
      "18\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1978 - accuracy: 0.9885\n",
      "19\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1971 - accuracy: 0.9875\n",
      "20\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2231 - accuracy: 0.9595\n",
      "21\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1460 - accuracy: 0.9875\n",
      "22\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1305 - accuracy: 0.9955\n",
      "23\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1155 - accuracy: 0.9945\n",
      "24\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1039 - accuracy: 0.9950\n",
      "25\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0897 - accuracy: 0.9960\n",
      "26\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.9975\n",
      "27\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0742 - accuracy: 0.9960\n",
      "28\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0678 - accuracy: 0.9975: 0s - l\n",
      "29\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0590 - accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "# train LSTM\n",
    "for i in range(n_epoch):\n",
    "    X, y = generate_data(n_samples, n_numbers, largest, alphabet)\n",
    "    print(i)\n",
    "    model.fit(X, y, epochs=1, batch_size=n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=14, Predicted=14\n",
      "Expected=15, Predicted=15\n",
      "Expected=12, Predicted=12\n",
      "Expected=12, Predicted=12\n",
      "Expected=13, Predicted=13\n",
      "Expected=15, Predicted=15\n",
      "Expected= 8, Predicted= 8\n",
      "Expected= 4, Predicted= 4\n",
      "Expected=19, Predicted=19\n",
      "Expected=13, Predicted=13\n",
      "Expected=15, Predicted=15\n",
      "Expected= 8, Predicted= 8\n",
      "Expected=13, Predicted=13\n",
      "Expected= 4, Predicted= 4\n",
      "Expected=16, Predicted=16\n",
      "Expected=13, Predicted=13\n",
      "Expected=16, Predicted=16\n",
      "Expected= 8, Predicted= 8\n",
      "Expected=14, Predicted=14\n",
      "Expected=16, Predicted=16\n"
     ]
    }
   ],
   "source": [
    "# evaluate on some new patterns\n",
    "X, y = generate_data(n_samples, n_numbers, largest, alphabet)\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "# calculate error\n",
    "expected = [invert(x, alphabet) for x in y]\n",
    "predicted = [invert(x, alphabet) for x in result]\n",
    "# show some examples\n",
    "for i in range(20):\n",
    "    print('Expected=%s, Predicted=%s' % (expected[i], predicted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extensions\n",
    "\n",
    "This section lists some natural extensions to this tutorial that you may wish to explore.\n",
    "\n",
    "   ***Integer Encoding***. Explore whether the problem can learn the problem better using an integer encoding alone. The ordinal relationship between most of the inputs may prove very useful.\n",
    "    \n",
    "   ***Variable Numbers***. Change the example to support a variable number of terms on each input sequence. This should be straightforward as long as you perform sufficient padding.\n",
    "    \n",
    "   ***Variable Mathematical Operations***. Change the example to vary the mathematical operation to allow the network to generalize even further.\n",
    "    Brackets. Allow the use of brackets along with other mathematical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "    https://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره پیشرفته یادگیری عمیق<br>علیرضا اخوان پور<br>  آبان و آذر 1399<br>\n",
    "</div>\n",
    "<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-GPU",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
